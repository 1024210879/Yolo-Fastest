[net]
batch=64
subdivisions=1
width=320
height=320
channels=3
momentum=0.949
decay=0.0005
angle=0
saturation=1.5
exposure=1.5
hue=.1


learning_rate=0.001
burn_in=4000
max_batches=200000
policy=steps
steps=150000,180000
scales=.1,.1



### CONV1 - 1 (1)
# conv1
[convolutional]
filters=9
size=3
pad=1
stride=2
batch_normalize=1
activation=leaky


### CONV2 - MBConv1 - 1 (1)
# conv2_1_expand
[convolutional]
filters=9
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv2_1_dwise
[convolutional]
groups=9
filters=9
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=2
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=9
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv2_1_linear
[convolutional]
filters=4
size=1
stride=1
pad=0
batch_normalize=1
activation=linear



### CONV3 - MBConv6 - 1 (2)
# conv2_2_expand
[convolutional]
filters=28
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv2_2_dwise
[convolutional]
groups=28
filters=28
size=3
pad=1
stride=2
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=8 (recommended r=16)
[convolutional]
filters=4
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=28
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv2_2_linear
[convolutional]
filters=7
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV3 - MBConv6 - 2 (2)
# conv3_1_expand
[convolutional]
filters=43
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv3_1_dwise
[convolutional]
groups=43
filters=43
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=2
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=43
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv3_1_linear
[convolutional]
filters=7
size=1
stride=1
pad=0
batch_normalize=1
activation=linear



### CONV4 - MBConv6 - 1 (2)
# dropout only before residual connection
[dropout]
probability=.2

# block_3_1
[shortcut]
from=-9
activation=linear

# conv_3_2_expand
[convolutional]
filters=43
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_3_2_dwise
[convolutional]
groups=43
filters=43
size=5
pad=1
stride=2
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=2
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=43
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_3_2_linear
[convolutional]
filters=12
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV4 - MBConv6 - 2 (2)
# conv_4_1_expand
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_4_1_dwise
[convolutional]
groups=57
filters=57
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=4
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=57
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_4_1_linear
[convolutional]
filters=12
size=1
stride=1
pad=0
batch_normalize=1
activation=linear




### CONV5 - MBConv6 - 1 (3)
# dropout only before residual connection
[dropout]
probability=.2

# block_4_2
[shortcut]
from=-9
activation=linear

# conv_4_3_expand
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_4_3_dwise
[convolutional]
groups=57
filters=57
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=4
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=57
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_4_3_linear
[convolutional]
filters=24
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV5 - MBConv6 - 2 (3)
# conv_4_4_expand
[convolutional]
filters=115
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_4_4_dwise
[convolutional]
groups=115
filters=115
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=7
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=115
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_4_4_linear
[convolutional]
filters=24
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV5 - MBConv6 - 3 (3)
# dropout only before residual connection
[dropout]
probability=.2

# block_4_4
[shortcut]
from=-9
activation=linear

# conv_4_5_expand
[convolutional]
filters=115
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_4_5_dwise
[convolutional]
groups=115
filters=115
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=7
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=115
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_4_5_linear
[convolutional]
filters=24
size=1
stride=1
pad=0
batch_normalize=1
activation=linear



### CONV6 - MBConv6 - 1 (3)
# dropout only before residual connection
[dropout]
probability=.2

# block_4_6
[shortcut]
from=-9
activation=linear

# conv_4_7_expand
[convolutional]
filters=115
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_4_7_dwise
[convolutional]
groups=115
filters=115
size=5
pad=1
stride=2
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=7
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=115
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_4_7_linear
[convolutional]
filters=33
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV6 - MBConv6 - 2 (3)
# conv_5_1_expand
[convolutional]
filters=172
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_5_1_dwise
[convolutional]
groups=172
filters=172
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=9
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=172
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_5_1_linear
[convolutional]
filters=33
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV6 - MBConv6 - 3 (3)
# dropout only before residual connection
[dropout]
probability=.2

# block_5_1
[shortcut]
from=-9
activation=linear

# conv_5_2_expand
[convolutional]
filters=172
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_5_2_dwise
[convolutional]
groups=172
filters=172
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=9
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=172
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_5_2_linear
[convolutional]
filters=33
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV7 - MBConv6 - 1 (4)
# dropout only before residual connection
[dropout]
probability=.2

# block_5_2
[shortcut]
from=-9
activation=linear

# conv_5_3_expand
[convolutional]
filters=172
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_5_3_dwise
[convolutional]
groups=172
filters=172
size=5
pad=1
stride=2
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=9
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=172
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_5_3_linear
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV7 - MBConv6 - 2 (4)
# conv_6_1_expand
[convolutional]
filters=288
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_6_1_dwise
[convolutional]
groups=288
filters=288
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=19
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=288
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_6_1_linear
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV7 - MBConv6 - 3 (4)
# dropout only before residual connection
[dropout]
probability=.2

# block_6_1
[shortcut]
from=-9
activation=linear

# conv_6_2_expand
[convolutional]
filters=288
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_6_2_dwise
[convolutional]
groups=288
filters=288
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=19
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=288
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_6_2_linear
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV7 - MBConv6 - 4 (4)
# dropout only before residual connection
[dropout]
probability=.2

# block_6_1
[shortcut]
from=-9
activation=linear

# conv_6_2_expand
[convolutional]
filters=288
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_6_2_dwise
[convolutional]
groups=288
filters=288
size=5
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=19
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=288
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_6_2_linear
[convolutional]
filters=57
size=1
stride=1
pad=0
batch_normalize=1
activation=linear



### CONV8 - MBConv6 - 1 (1)
# dropout only before residual connection
[dropout]
probability=.2

# block_6_2
[shortcut]
from=-9
activation=linear

# conv_6_3_expand
[convolutional]
filters=288
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

# conv_6_3_dwise
[convolutional]
groups=288
filters=288
size=3
stride=1
pad=1
batch_normalize=1
activation=leaky


#squeeze-n-excitation
[avgpool]

# squeeze ratio r=16 (recommended r=16)
[convolutional]
filters=19
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=288
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4


# conv_6_3_linear
[convolutional]
filters=96
size=1
stride=1
pad=0
batch_normalize=1
activation=linear


### CONV9 - Conv2d 1x1
# conv_6_4
[convolutional]
filters=128
size=1
stride=1
pad=0
batch_normalize=1
activation=leaky

################################################################

[convolutional]
filters=128
size=3
groups=128
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=128
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=128
size=3
groups=128
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=128
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear


[yolo]
mask = 3,4,5
anchors = 26, 48,  67, 84,  72,175, 189,126, 137,236, 265,259
classes=20
num=6
jitter=.15
ignore_thresh = .5
truth_thresh = 1
random=0
#################
scale_x_y = 1.0
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
###################


[route]
layers = -7

[upsample]
stride = 2

[route]
layers=-1,89

[convolutional]
filters=96
size=1
stride=1
pad=1
batch_normalize=1
activation=leaky

#squeeze-n-excitation
[avgpool]

# squeeze ratio r=4 (recommended r=16)
[convolutional]
filters=48
size=1
stride=1
activation=leaky

# excitation
[convolutional]
filters=96
size=1
stride=1
activation=logistic

# multiply channels
[scale_channels]
from=-4

[convolutional]
filters=96
size=3
groups=96
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=96
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
filters=96
size=3
groups=96
stride=1
pad=1
batch_normalize=1
activation=leaky

[convolutional]
filters=192
size=1
stride=1
pad=1
batch_normalize=1
activation=linear

[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear


[yolo]
mask = 0,1,2
anchors = 26, 48,  67, 84,  72,175, 189,126, 137,236, 265,259
classes=20
num=6
jitter=.15
ignore_thresh = .5
truth_thresh = 1
random=0
#################
scale_x_y = 1.00
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6

